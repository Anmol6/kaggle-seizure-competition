{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sys import getsizeof\n",
    "from pandas import DataFrame\n",
    "import scipy.signal\n",
    "from split_safe import SafeDataFilter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_scaler import scale_across_features, scale_across_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(719, 16, 7, 10)\n",
      "(216, 16, 7, 10)\n",
      "(1986, 16, 7, 10)\n",
      "(1002, 16, 7, 10)\n",
      "(2058, 16, 7, 10)\n",
      "(690, 16, 7, 10)\n",
      "(array([    0,     1,     2, ..., 28802, 28803, 28804]),)\n",
      "(array([], dtype=int64),)\n",
      "('final: ', (719, 10, 112))\n",
      "('final: ', (719, 2))\n"
     ]
    }
   ],
   "source": [
    "X_train1 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/train_1_npy/X_new.npy')\n",
    "X_train2 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/train_2_npy/X_new.npy')\n",
    "X_train3 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/train_3_npy/X_new.npy')\n",
    "y_train1 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/train_1_npy/y_new.npy')\n",
    "y_train2 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/train_2_npy/y_new.npy')\n",
    "y_train3 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/train_3_npy/y_new.npy')\n",
    "\n",
    "X_test1 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/test_1_new/X_new.npy')\n",
    "X_test2 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/test_2_new/X_new.npy')\n",
    "X_test3 = np.load('/Users/Anuar_The_Great/desktop/ML/CNN/test_3_new/X_new.npy')\n",
    "\n",
    "\n",
    "\n",
    "X_train1[X_train1 < -100000] = 0\n",
    "X_train2[X_train2 < -100000] = 0\n",
    "X_train3[X_train3 < -100000] = 0\n",
    "\n",
    "X_test1[X_test1 < -100000] = 0\n",
    "X_test2[X_test2 < -100000] = 0\n",
    "X_test3[X_test3 < -100000] = 0\n",
    "\n",
    "X_train1 = np.abs(X_train1)\n",
    "X_train2 = np.abs(X_train2)\n",
    "X_train3 = np.abs(X_train3)\n",
    "\n",
    "X_test1 = np.abs(X_test1)\n",
    "X_test2 = np.abs(X_test2)\n",
    "X_test3 = np.abs(X_test3)\n",
    "\n",
    "X_trains = [X_train1, X_train2, X_train3]\n",
    "X_tests = [X_test1, X_test2, X_test3]\n",
    "y_trains = [y_train1, y_train2, y_train3]\n",
    "pos_weight = []\n",
    "    \n",
    "# Accepts X's of shape (examples, channels, time-windows, bins)\n",
    "# X_trains and X_tests must be list\n",
    "def scale_reshape(X_trains, X_tests):\n",
    "    # applying scale_across_time\n",
    "    for i, X in enumerate(X_trains):\n",
    "        X_train = X.swapaxes(2, 3)\n",
    "        X_test = X_tests[i]\n",
    "        X_test = X_test.swapaxes(2, 3)\n",
    "        X_trains[i], scalers = scale_across_time(X_train, X_test)\n",
    "        X_tests[i], additional_scalers = scale_across_time(X_test, scalers=scalers)\n",
    "    # swaping the axis back and reshaping the features\n",
    "    for i, X in enumerate(X_trains):\n",
    "        X_trains[i] = X.swapaxes(2, 3)\n",
    "        X_trains[i] = X.reshape((X.shape[0], 10, 112))   \n",
    "        X = X_tests[i]\n",
    "        X_tests[i] = X.swapaxes(2, 3)\n",
    "        X_tests[i] = X.reshape((X.shape[0], 10, 112)) \n",
    "    return X_trains, X_tests, scalers\n",
    "    \n",
    "X_trains, X_tests, scalers = scale_reshape(X_trains, X_tests)\n",
    "# Computing y's one-hot vectors and pos_weight\n",
    "for i, X in enumerate(X_trains):\n",
    "    ys = np.zeros((y_trains[i].shape[0], 2))\n",
    "    ys[:, 1] = (y_trains[i] > 0).reshape(y_trains[i].shape[0],)\n",
    "    ys[:, 0] = (y_trains[i] < 1).reshape(y_trains[i].shape[0],)\n",
    "    y_trains[i] = ys\n",
    "    pos_weight.append(np.sum(y_trains[i][:,0])/np.sum(y_trains[i][:,1]))\n",
    "    \n",
    "\n",
    "# Checking:\n",
    "print(np.nonzero(X_trains[0][X_trains[0] > 50]))\n",
    "print(np.nonzero(X_trains[0][X_trains[0] < -5]))\n",
    "print(\"final: \", X_trains[0].shape)\n",
    "print(\"final: \", y_trains[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "class GlobalPoolLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        #self.output_dim = output_dim\n",
    "        super(GlobalPoolLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        #self.built = True\n",
    "        super(GlobalPoolLayer, self).build()\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        x += 1e-06\n",
    "        avg = x.mean(3, dtype='float32')\n",
    "        max_val = x.max(3)\n",
    "        min_val = x.min(3)\n",
    "        var = x.var(3)\n",
    "        geom_mean = K.exp(K.mean(K.log(x), axis=3, dtype='float32'))\n",
    "        l2_norm = x.norm(2, axis=3)\n",
    "        output = K.concatenate([avg, max_val, min_val, var, geom_mean, l2_norm], axis=2)\n",
    "        return output\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Convolution1D\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy.random import randint, random\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# create your model using this function\n",
    "def create_model(nb_filter1=16, nb_filter2=32, activation1='relu', l2_weight1=0.0, l2_weight2=0.0,\n",
    "                 dropout_rate=0.3, optimizer='adam', nb_epoch=10, hidden_dims=112):\n",
    "    #batch_size = 100\n",
    "    filter_length = 1\n",
    "    n = X_train.shape[0]\n",
    "    \n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(nb_filter=nb_filter1,\n",
    "                            filter_length=filter_length,\n",
    "                            init='glorot_normal',\n",
    "                            border_mode='valid',\n",
    "                            activation=activation1,\n",
    "                            subsample_length=1,\n",
    "                            W_regularizer=l2(l2_weight1),\n",
    "                            input_shape=(10, 112)))\n",
    "    \n",
    "    model.add(Convolution1D(nb_filter=nb_filter2,\n",
    "                            filter_length=1,\n",
    "                            init='glorot_normal',\n",
    "                            border_mode='valid',\n",
    "                            subsample_length=1,\n",
    "                            W_regularizer=l2(l2_weight2),\n",
    "                            activation=activation1))    \n",
    "\n",
    "    model.add(Reshape((nb_filter2*10,)))\n",
    "    model.add(Dense(hidden_dims))\n",
    "    model.add(Activation(activation1))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    #model.add(GlobalPoolLayer())\n",
    "    #model.add(Dense(hidden_dims))\n",
    "    #model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model(16, 32, 'sigmoid', 0, 0, 0.3, 'adam', 20, 36)\n",
    "model_result = model.fit(X_trains[2], y_trains[2], class_weight={0: 1.0, 1: pos_weight[2]}, verbose=2, nb_epoch=100)\n",
    "\n",
    "preds = model_result.model.predict_classes(X_trains[2])\n",
    "#preds_submission = np.argmax(preds, axis=1).astype('int32')\n",
    "\n",
    "print(\"\\n\")\n",
    "print(roc_auc_score(y_trains[2][:, 1], preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
